{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "from threading import Thread\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = ['url1-', 'url1-', 'url2-', 'url3-', 'url4-', 'url5-', 'url6-', 'url7-', 'url8-', 'url9-', 'url10-']\n",
    "seen = set()\n",
    "\n",
    "url_queue = Queue()\n",
    "for url in urls:\n",
    "    url_queue.put(url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_queue = Queue()\n",
    "cleaned_queue = Queue()\n",
    "deduplicated_queue = Queue()\n",
    "insights_queue = Queue()\n",
    "decisions_queue = Queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraper():\n",
    "    while True:\n",
    "        time.sleep(random.randrange(0,2))\n",
    "        url = url_queue.get()\n",
    "        print(\"Scraping {}\".format(url))\n",
    "        scraped_queue.put(url[3:])\n",
    "        \n",
    "def cleaner():\n",
    "    while True:\n",
    "        time.sleep(random.randrange(2,4))\n",
    "        raw = scraped_queue.get()\n",
    "        print(\"Cleaning {}\".format(raw))\n",
    "        cleaned_queue.put(raw.replace(\"-\", \"\"))\n",
    "        \n",
    "def deduplicator():\n",
    "     while True:\n",
    "        time.sleep(random.randrange(4,6))\n",
    "        cleaned = cleaned_queue.get()\n",
    "        print(\"Deduplicating {}\".format(cleaned))\n",
    "        if cleaned not in seen:\n",
    "            deduplicated_queue.put(cleaned)\n",
    "            seen.add(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyzer():\n",
    "    while True:\n",
    "        time.sleep(random.randrange(1,4))\n",
    "        unique = deduplicated_queue.get()\n",
    "        print(\"Analyzing {}\".format(unique))\n",
    "        n = int(unique)\n",
    "        if n % 2 == 0:\n",
    "            insights_queue.put(-n)\n",
    "        else:\n",
    "            insights_queue.put(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_maker():\n",
    "    while True:\n",
    "        time.sleep(random.randrange(1,4))\n",
    "        insight = insights_queue.get()\n",
    "        print(\"Deciding {}\".format(insight))\n",
    "        if insight > 0:\n",
    "            decisions_queue.put(\"Buy {}\".format(insight))\n",
    "        else:\n",
    "            decisions_queue.put(\"Sell {}\".format(-insight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trader():\n",
    "    while True:\n",
    "        time.sleep(random.randrange(1,4))\n",
    "        trade = decisions_queue.get()\n",
    "        print(\"Trading {}\".format(trade))\n",
    "        print(trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper_worker = Thread(target=scraper)\n",
    "cleaner_worker = Thread(target=cleaner)\n",
    "deduplicator_worker = Thread(target=deduplicator)\n",
    "analyzer_worker = Thread(target=analyzer)\n",
    "decision_maker_worker = Thread(target=decision_maker)\n",
    "trader_worker = Thread(target=trader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping url1-\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping url1-\n",
      "Scraping url2-\n",
      "Cleaning 1-\n",
      "Scraping url3-\n",
      "Scraping url4-\n",
      "Scraping url5-\n",
      "Deduplicating 1Scraping url6-\n",
      "\n",
      "Analyzing 1\n",
      "Deciding 1\n",
      "Trading Buy 1\n",
      "Buy 1\n",
      "Cleaning 1-\n",
      "Scraping url7-\n",
      "Scraping url8-\n",
      "Cleaning 2-\n",
      "Scraping url9-\n",
      "Scraping url10-\n",
      "Deduplicating 1\n",
      "Cleaning 3-\n",
      "Cleaning 4-\n",
      "Deduplicating 2\n",
      "Analyzing 2\n",
      "Deciding -2\n",
      "Trading Sell 2\n",
      "Sell 2\n",
      "Cleaning 5-\n",
      "Cleaning 6-\n",
      "Deduplicating 3\n",
      "Analyzing 3\n",
      "Deciding 3\n",
      "Trading Buy 3\n",
      "Buy 3\n",
      "Cleaning 7-\n",
      "Cleaning 8-\n",
      "Deduplicating 4\n",
      "Analyzing 4\n",
      "Deciding -4\n",
      "Trading Sell 4\n",
      "Sell 4\n",
      "Cleaning 9-\n",
      "Cleaning 10-\n",
      "Deduplicating 5\n",
      "Analyzing 5\n",
      "Deciding 5\n",
      "Trading Buy 5\n",
      "Buy 5\n",
      "Deduplicating 6\n",
      "Analyzing 6\n",
      "Deciding -6\n",
      "Trading Sell 6\n",
      "Sell 6\n",
      "Deduplicating 7\n",
      "Analyzing 7\n",
      "Deciding 7\n",
      "Trading Buy 7\n",
      "Buy 7\n",
      "Deduplicating 8\n",
      "Analyzing 8\n",
      "Deciding -8\n",
      "Trading Sell 8\n",
      "Sell 8\n",
      "Deduplicating 9\n",
      "Analyzing 9\n",
      "Deciding 9\n",
      "Trading Buy 9\n",
      "Buy 9\n",
      "Deduplicating 10\n",
      "Analyzing 10\n",
      "Deciding -10\n",
      "Trading Sell 10\n",
      "Sell 10\n"
     ]
    }
   ],
   "source": [
    "threads = [\n",
    "    scraper_worker, cleaner_worker, deduplicator_worker, analyzer_worker, decision_maker_worker, trader_worker\n",
    "]\n",
    "\n",
    "[t.start() for t in threads]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
